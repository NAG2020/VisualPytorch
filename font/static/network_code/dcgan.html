<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>unet</title></head>
<body><pre><code class='language-python' lang='python'>import os
import time

import torch.nn as nn
import torch.optim as optim
import torch.utils.data
import imageio
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib
matplotlib.use(&#39;Agg&#39;)
from matplotlib import pyplot as plt
from tools.common_tools import set_seed
from torch.utils.data import DataLoader
from tools.my_dataset import CelebADataset
from tools.dcgan import Discriminator, Generator




def remove_module(state_dict_g):
    # remove module.
    from collections import OrderedDict

    new_state_dict = OrderedDict()
    for k, v in state_dict_g.items():
        namekey = k[7:] if k.startswith(&#39;module.&#39;) else k
        new_state_dict[namekey] = v

    return new_state_dict


def gcgan(pic_name, pkl_path):
    # config
    num_img = 64
    nrow = 8
    noise_continue = True

    tic = time.time()
    device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
    path_checkpoint = pkl_path + &quot;checkpoint_14_epoch.pkl&quot;
    time_tic = time.time()
    nz = 100

    # step 1: data
    fixed_noise = torch.randn(num_img, nz, 1, 1, device=device)

    if noise_continue:
        fixed_noise[0, ...] = torch.randn(1, nz, 1, 1, device=device)
        delta = torch.randn(1, nz, 1, 1, device=device) - fixed_noise[0, ...]
        delta /= num_img

        for i in range(1, num_img):
            fixed_noise[i, ...] = fixed_noise[i - 1, ...] + delta

    # step 2: model
    net_g = Generator(nz=nz, ngf=128, nc=3)
    # net_d = Discriminator(nc=nc, ndf=ndf)
    checkpoint = torch.load(path_checkpoint, map_location=&quot;cpu&quot;)

    state_dict_g = checkpoint[&quot;g_model_state_dict&quot;]
    state_dict_g = remove_module(state_dict_g)
    net_g.load_state_dict(state_dict_g)
    net_g.to(device)
    # net_d.load_state_dict(checkpoint[&quot;d_model_state_dict&quot;])
    # net_d.to(device)

    # step3: inference
    with torch.no_grad():
        fake_data = net_g(fixed_noise).detach().cpu()
    img_grid = vutils.make_grid(fake_data, padding=2, normalize=True, nrow=nrow).numpy()
    img_grid = np.transpose(img_grid, (1, 2, 0))
    plt.imshow(img_grid)
    pic_out = pic_name
    plt.savefig(pic_out)

    plt.close()

    return {&quot;addr&quot;: pic_out, &quot;time&quot;: round(time.time() - tic, 2)}


if __name__ == &quot;__main__&quot;:
    print(gcgan(&quot;test.jpg&quot;, &#39;./&#39;))

</code></pre>
<p>&nbsp;</p>
</body>
</html>